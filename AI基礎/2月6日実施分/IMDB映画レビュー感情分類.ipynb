{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB映画レビュー感情分類.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZc-I-_AVayU"
      },
      "source": [
        "IMDB データセットをダウンロードする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5L0pt1MTDA1"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcRIIH6qVjZM"
      },
      "source": [
        "訓練用データの中身をのぞいてみる\n",
        "\n",
        "0がnegativeで、1がpositive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhIH-vejTJH7"
      },
      "source": [
        "train_data[0]\n",
        "train_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQBh1d6EVzbr"
      },
      "source": [
        "整数のインデックスになっているデータをテキストデータに変換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzTyWPOHTR7M"
      },
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tk3jiDbV0ST"
      },
      "source": [
        "ダウンロードした辞書によって、整数のインデックスのリストで表されているデータを文字列にデコードします。\n",
        "3を指定しているのは、0,1,2が学習には不要な文字のインデックスになっているためです。１番目のデータのテキストを表示してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYP4_0veTZO0"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
        "\n",
        "decoded_review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_2_ejIDWAur"
      },
      "source": [
        "データは、整数のインデックスになっており、このままでは学習の入力に使えないので、One-hotベクトルに変換します。ここでは、One-hotベクトルの次元は10000とし、出現した単語に1を割り当てます。このOne-hotベクトルへの変換では、単語の出現頻度や並び順といった情報は落ちています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG_rLzy8Tcds"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqYPNe_kWHAL"
      },
      "source": [
        "またラベルも整数ではなく、浮動小数に変換します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNFWUiIdTjX8"
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')\n",
        "\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA3q3AytWMBD"
      },
      "source": [
        "次に学習させるネットワークを定義します。layers.Denseを使用して、全結合層のみのネットワークとなります。ネットワークとしては、3層の浅いニューラルネットで、1,2番目の隠れ層のユニットは16、活性化関数はreluを使用します。また、input_shapeにOne-hotベクトルの次元を指定します。２クラス分類なので、最後の層の出力はsigmoid層で、どちらのクラスであるかの確率を出力します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER5LHjZHTny0"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9yuzxfTWR4L"
      },
      "source": [
        "モデル情報は以下のように出力できます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExMjjnBxTrqc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaIJMyNaWVrL"
      },
      "source": [
        "学習の際のoptimizer、損失関数、metricsを指定します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NejwJ4HiTvg1"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBH0ySGNWbZr"
      },
      "source": [
        "学習データをtrain用と、validation用に分けます。今回はデータの前から10000個をvalidation用にしました。ここの分け方は、positiveとnegativeの数に不均衡が起きないようにランダムに分けたほうが精度がよくなるかも知れません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C14sCKQoT0EM"
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed5ZgSxnWhRb"
      },
      "source": [
        "学習は以下のようにmodel.fitを実行して行います。epochsは20、バッチサイズは512に今回は設定しました。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SB30hCvT3RO"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))\n",
        "history_dict = history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCB0O9AbWk-D"
      },
      "source": [
        "model.fitはhistory objectを返します。history objectはメンバのhistoryを持っていて学習の際の情報を辞書として持っています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAvj-QLLUCss"
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKzVtBvJWqZb"
      },
      "source": [
        "lossの変化をグラフに表示してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_q1tM1WUHJM"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "acc = history_dict['accuracy']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHrB9wJVWs4j"
      },
      "source": [
        "精度についても以下のコードを実行して確認してみます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUXTVUGqUTVs"
      },
      "source": [
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxVrRG_iWyh7"
      },
      "source": [
        "testデータに対する精度を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UZAMpjUnVE"
      },
      "source": [
        "results = model.evaluate(x_test, y_test)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}